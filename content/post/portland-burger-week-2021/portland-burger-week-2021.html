---
title: Introduction Into Web Scraping with Portland Burger Week
author: ''
date: '2021-08-03'
slug: 'portland-burger-week-2021'
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-08-03T16:40:44-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
---



<p>I take the Portland food weeks very seriously. My partner and I make a list of our must-trys and then I make out plan of attack. We usually hit up 2-3 places a night until we’ve exhausted all the places that we wanted to try. Burger Week is coming up in a couple weeks and I wanted to streamline things a bit: I wanted a spreadsheet of all of the burgers. I knew that web scraping in R was a thing but honestly I had always been a bit intimidated. I had some free time on my hands and figured: now is the time to learn. So I googled a few tutorials and dove straight in. It wound up being so much easier than I thought it would be. Let’s learn together.</p>
<p>The tutorial I wound up reading in most detail is <a href="https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/">this one</a>. The reason I liked this tutorial is that it turned me on to this nifty little tool to kinda cheat a little - it’s a Chrome extension called <a href="https://selectorgadget.com/">SelectorGadget</a> that makes finding the relevant CSS elements easy peasy.</p>
<p>Step 1: install the SelectorGadget extension <a href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb">here</a>.</p>
<p>Step 2: In R, install <code>{rvest}</code>.</p>
<pre class="r"><code>install.packages(&quot;rvest&quot;)</code></pre>
<p>Step 3: Have R read in your website of interest - mine is the <a href="https://www.portlandmercury.com/sponsored/burgerweek2021">Portland 2021 Burger Week list</a>.</p>
<pre class="r"><code>library(rvest)
library(tidyverse)
url &lt;- &#39;https://www.portlandmercury.com/sponsored/burgerweek2021&#39;
webpage &lt;- read_html(url)</code></pre>
<p>Step 4: Now go to your website and activate SelectorGadget. Click on the element you want to scrape. For me, I did the restaurant names first. Scroll through the whole page and make sure the only things highlighted green/yellow are things you want. If there are any other elements highlighted, click on them and they will turn red/be excluded.</p>
<p><img src="restaurant-name.JPG" style="width:50.0%" /></p>
<p>The SelectorGadget tells me that the CSS element that I want is <code>.headline a</code>. Back in R, lets use that to scrape the restaurant names. Use <code>html_nodes()</code> to scrape the element and <code>html_text2()</code> to read the text.</p>
<pre class="r"><code>restaurant &lt;- html_nodes(webpage,&#39;.headline a&#39;) %&gt;% html_text2()
restaurant</code></pre>
<pre><code>##  [1] &quot;New Seasons&quot;                       &quot;Bar Bar&quot;                          
##  [3] &quot;Boke Bowl&quot;                         &quot;Bread &amp; Ink Cafe&quot;                 
##  [5] &quot;BrunchBox&quot;                         &quot;Church&quot;                           
##  [7] &quot;Danwei Canting&quot;                    &quot;Farmer and the Beast&quot;             
##  [9] &quot;Fills&quot;                             &quot;Fuller&#39;s Burger Shack&quot;            
## [11] &quot;Haymaker&quot;                          &quot;Holler&quot;                           
## [13] &quot;Holy Goat&quot;                         &quot;HOME, A BAR&quot;                      
## [15] &quot;Hop Capital Brewing PDX&quot;           &quot;Landmark Saloon&quot;                  
## [17] &quot;Laurelwood Public House &amp; Brewery&quot; &quot;Local 66 Bar and Grill&quot;           
## [19] &quot;Loyal Legion&quot;                      &quot;Mad Greek Deli&quot;                   
## [21] &quot;Mighty Moe&#39;s Tanker&quot;               &quot;Moreland Ale House&quot;               
## [23] &quot;Next Level Burger&quot;                 &quot;Nick&#39;s Famous Coney Island&quot;       
## [25] &quot;Paymaster Lounge&quot;                  &quot;Piccone&#39;s Corner&quot;                 
## [27] &quot;Ponderosa Lounge &amp; Grill&quot;          &quot;Portland Burger&quot;                  
## [29] &quot;Rocky&#39;s Sports And Spirits&quot;        &quot;Salvador Molly&#39;s&quot;                 
## [31] &quot;show bar&quot;                          &quot;Steakadelphia&quot;                    
## [33] &quot;Sunny&#39;s Diner&quot;                     &quot;West Coast Grocery Company&quot;       
## [35] &quot;Ya Hala&quot;                           &quot;Yur&#39;s Bar and Grill&quot;</code></pre>
<p>Step 5: Do the same for the rest of the elements you want and you’re good to go! Here’s my code in entirety:</p>
<pre class="r"><code>library(tidyverse)
library(rvest)

url &lt;- &#39;https://www.portlandmercury.com/sponsored/burgerweek2021&#39;
webpage &lt;- read_html(url)

restaurant &lt;- html_nodes(webpage,&#39;.headline a&#39;) %&gt;% html_text2()
burger_name &lt;- html_nodes(webpage, &#39;.blog-body p:nth-child(1)&#39;) %&gt;% html_text2()
description &lt;- html_nodes(webpage, &#39;.blog-body p:nth-child(2)&#39;) %&gt;% html_text2()
address_hours &lt;- html_nodes(webpage, &#39;p:nth-child(5) , p:nth-child(4)&#39;) %&gt;% html_text2()

# ugh sometimes address is 4th...sometimes it&#39;s 5th...must filter.
address_hours &lt;- as.tibble(address_hours) %&gt;% filter(grepl(&quot;Address/Hours of Availability&quot;,value)) %&gt;% pull()

burger_week &lt;- tibble(restaurant = restaurant,
                      burger_name = burger_name,
                      description = description,
                      address_hours = address_hours)
# cleaning
burger_week &lt;- burger_week %&gt;% 
  separate(burger_name, into = c(&quot;trash&quot;, &quot;burger_name&quot;), sep = &quot;:&quot;, extra = &quot;merge&quot;) %&gt;% 
  separate(description, into = c(&quot;trash&quot;, &quot;description&quot;), sep = &quot;:&quot;, extra = &quot;merge&quot;) %&gt;%
  separate(address_hours, into = c(&quot;trash&quot;, &quot;address_hours&quot;), sep = &quot;:&quot;, extra = &quot;merge&quot;) %&gt;%
  select(restaurant, burger_name, description, address_hours)

write_csv(x = burger_week, path = &quot;burger_week_2021.csv&quot;)</code></pre>
<p>You can find the resultant .csv file on my <a href="https://github.com/jnjahncke/food-weeks/tree/main/burger%20week%202021">github</a>.</p>
<p>Happy scraping!</p>
